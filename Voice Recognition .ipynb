{"cells":[{"cell_type":"markdown","id":"790fdfb9","metadata":{"id":"790fdfb9"},"source":["# SPEECH RECOGNITION TUTORIAL\n","\n","## OVERVIEW\n","\n","### HOW SPEECH RECOGNITION WORKS?\n","\n","##### Speech recognition systems have come a long way since their early days in the 1950s. They can now recognize speech from multiple speakers with large vocabularies. The process involves converting speech into digital data, using techniques like Hidden Markov Models (HMM) to transcribe audio into text. Neural networks and voice activity detectors are used to simplify and optimize the speech recognition process. "]},{"cell_type":"markdown","id":"fe7cb0b7","metadata":{"id":"fe7cb0b7"},"source":["## Installing Speech Recognition"]},{"cell_type":"code","execution_count":null,"id":"3ca34d70","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3ca34d70","executionInfo":{"status":"error","timestamp":1686287508941,"user_tz":-330,"elapsed":2,"user":{"displayName":"Imran Shaikh","userId":"14282954289375036087"}},"outputId":"34176463-922a-469d-c3c4-0111349eba49"},"outputs":[{"output_type":"stream","name":"stderr","text":["UsageError: Cell magic `%%cmd` not found.\n"]}],"source":["%%cmd\n","pip install SpeechRecognition"]},{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"teuRvQyKkT0_","executionInfo":{"status":"error","timestamp":1686287501520,"user_tz":-330,"elapsed":11,"user":{"displayName":"Imran Shaikh","userId":"14282954289375036087"}},"outputId":"30ba5948-3e92-4518-9500-7407e2f55d3f"},"id":"teuRvQyKkT0_","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["UsageError: Cell magic `%%cmd` not found.\n"]}]},{"cell_type":"markdown","id":"2834bcee","metadata":{"id":"2834bcee"},"source":["## Verifying the installation"]},{"cell_type":"code","execution_count":null,"id":"ea9d6b69","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"ea9d6b69","executionInfo":{"status":"ok","timestamp":1686287469976,"user_tz":-330,"elapsed":6,"user":{"displayName":"Imran Shaikh","userId":"14282954289375036087"}},"outputId":"aa06cb72-525a-4296-c964-bdf02c6907ac"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'3.10.0'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}],"source":["import speech_recognition as sr\n","sr.__version__\n"]},{"cell_type":"markdown","id":"3c23d440","metadata":{"id":"3c23d440"},"source":["## WORKING WITH THE AUDIO FILES\n","\n","### Supported File Types\n","\n","##### - WAV: must be in PCM/LPCM format\n","##### - AIFF\n","##### - AIFF-C\n","##### - FLAC: must be native FLAC format; OGG-FLAC is not supported\n","\n","#### First we downloaded an audio file and save it to the same directory, named \"Example audio file.wav\". Here we are going to use Recognizer class. \n"]},{"cell_type":"code","execution_count":10,"id":"7fbac209","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7fbac209","executionInfo":{"status":"ok","timestamp":1686287620795,"user_tz":-330,"elapsed":14,"user":{"displayName":"Imran Shaikh","userId":"14282954289375036087"}},"outputId":"5d6a89fe-6448-4758-8180-3116797d3a5a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["speech_recognition.audio.AudioData"]},"metadata":{},"execution_count":10}],"source":["#Using record() to Capture Data From a File\n","\n","r = sr.Recognizer()\n","\n","Example_audio_file = sr.AudioFile('Example audio file.wav')\n","with Example_audio_file as source:\n","   audio = r.record(source)\n","\n","#Checking the type of audio\n","\n","type(audio)"]},{"cell_type":"code","execution_count":11,"id":"8360528a","metadata":{"id":"8360528a","outputId":"adfc066a-3a0e-40f7-efc3-4ceda56d3d99","colab":{"base_uri":"https://localhost:8080/","height":87},"executionInfo":{"status":"ok","timestamp":1686287633704,"user_tz":-330,"elapsed":10176,"user":{"displayName":"Imran Shaikh","userId":"14282954289375036087"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'does smallpox not a hole in the sock the fish twisted and turned on the bent hook press the pants and sew a button on the vest the Swan Dive was Far short of perfect the beauty of the view stunned the young boy two blue fish swim in the tank her purse was full of useless trash the cult reared and through the tall rider is snowed rain and hail the same morning read verse out loud for pleasure'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":11}],"source":["#Recognizing speech in the audio\n","\n","r.recognize_google(audio)"]},{"cell_type":"code","execution_count":12,"id":"43876c71","metadata":{"id":"43876c71","outputId":"c08d674a-c714-42b6-9667-3b52eeb91eb2","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1686287641201,"user_tz":-330,"elapsed":1712,"user":{"displayName":"Imran Shaikh","userId":"14282954289375036087"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'twisted and turned on the bent hook'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":12}],"source":["#Capturing Segments With offset and duration\n","\n","with Example_audio_file as source:\n","    audio1 = r.record(source, duration=4)\n","    audio2 = r.record(source, duration=4)\n","\n","r.recognize_google(audio1)\n","r.recognize_google(audio2)\n","\n","#NOTE - The record() method, when used inside a with block, always moves ahead in the file stream. This means that if you record once for four seconds and then record again for four seconds, the second time returns the four seconds of audio after the first four seconds.\n"]},{"cell_type":"markdown","id":"6b79b151","metadata":{"id":"6b79b151"},"source":["#### The record() method, with the offset keyword argument, allows specifying a specific starting point in seconds to ignore from the beginning of the file before starting the recording."]},{"cell_type":"code","execution_count":13,"id":"bb891436","metadata":{"id":"bb891436","outputId":"b205d114-05a2-45ca-ec45-0536a05ecec7","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1686287646427,"user_tz":-330,"elapsed":1037,"user":{"displayName":"Imran Shaikh","userId":"14282954289375036087"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'twisted and turned on the bed'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":13}],"source":["#To capture only the second phrase in the file, you could start with an offset of four seconds and record for, say, three seconds.\n","\n","with Example_audio_file as source:\n","    r.adjust_for_ambient_noise(source)\n","#Using above method to reduce noise in the audio file\n","\n","    audio = r.record(source, offset=4, duration=3)\n","\n","r.recognize_google(audio)\n","\n","#NOTE - Use offset and duration carefully to avoid inaccurate transcriptions."]},{"cell_type":"markdown","id":"ee1e651d","metadata":{"id":"ee1e651d"},"source":["## WORKING WITH MICROPHONES\n","\n","##### In the above sessions we used only Recognizer class but now we are even going to use The Microphone class\n","\n","### INSTALLING PyAudio"]},{"cell_type":"code","execution_count":14,"id":"e7c3df45","metadata":{"id":"e7c3df45","outputId":"81db3dc2-e2ec-4bad-f8eb-4126cfcc309d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"error","timestamp":1686287651077,"user_tz":-330,"elapsed":3,"user":{"displayName":"Imran Shaikh","userId":"14282954289375036087"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["UsageError: Cell magic `%%cmd` not found.\n"]}],"source":["%%cmd\n","pip install pyaudio"]},{"cell_type":"code","execution_count":null,"id":"d5b3e219","metadata":{"id":"d5b3e219","outputId":"54f4871e-9e4e-446d-f4f3-a0089cd17b08"},"outputs":[{"data":{"text/plain":["['Microsoft Sound Mapper - Input',\n"," 'Microphone Array (Realtek(R) Au',\n"," 'Microsoft Sound Mapper - Output',\n"," 'Speakers (Realtek(R) Audio)',\n"," 'Primary Sound Capture Driver',\n"," 'Microphone Array (Realtek(R) Audio)',\n"," 'Primary Sound Driver',\n"," 'Speakers (Realtek(R) Audio)',\n"," 'Speakers (Realtek(R) Audio)',\n"," 'Microphone Array (Realtek(R) Audio)',\n"," 'Microphone Array (Realtek HD Audio Mic Array input)',\n"," 'Headphones 1 (Realtek HD Audio 2nd output with HAP)',\n"," 'Headphones 2 (Realtek HD Audio 2nd output with HAP)',\n"," 'PC Speaker (Realtek HD Audio 2nd output with HAP)',\n"," 'Stereo Mix (Realtek HD Audio Stereo input)',\n"," 'Speakers 1 (Realtek HD Audio output with HAP)',\n"," 'Speakers 2 (Realtek HD Audio output with HAP)',\n"," 'PC Speaker (Realtek HD Audio output with HAP)',\n"," 'Microphone (Realtek HD Audio Mic input)']"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["#For systems without a default microphone, specify the desired device index by calling\n","\n","sr.Microphone.list_microphone_names()\n","\n","#You can choose which one to use by supplying a device index. For Eg. mic = sr.Microphone(device_index=3)"]},{"cell_type":"code","execution_count":null,"id":"37612d83","metadata":{"id":"37612d83","outputId":"b616a1f1-a147-4b2f-d632-40cfd37de494"},"outputs":[{"data":{"text/plain":["'hello my name is Harsh'"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["#Using listen() to Capture Microphone Input\n","\n","import speech_recognition as sr\n","r = sr.Recognizer()\n","mic = sr.Microphone()\n","with mic as source:\n","    r.adjust_for_ambient_noise(source)\n","    audio = r.listen(source)\n","    \n","r.recognize_google(audio)"]},{"cell_type":"code","execution_count":null,"id":"292d750e","metadata":{"id":"292d750e","outputId":"efb2260d-09e3-4c59-ac98-6f5e72ce946c"},"outputs":[{"ename":"UnknownValueError","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mUnknownValueError\u001b[0m                         Traceback (most recent call last)","Input \u001b[1;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     r\u001b[38;5;241m.\u001b[39madjust_for_ambient_noise(source)\n\u001b[0;32m      8\u001b[0m     audio \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mlisten(source)\n\u001b[1;32m---> 10\u001b[0m \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize_google\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\speech_recognition\\__init__.py:728\u001b[0m, in \u001b[0;36mRecognizer.recognize_google\u001b[1;34m(self, audio_data, key, language, pfilter, show_all, with_confidence)\u001b[0m\n\u001b[0;32m    725\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m show_all:\n\u001b[0;32m    726\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m actual_result\n\u001b[1;32m--> 728\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(actual_result, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(actual_result\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malternative\u001b[39m\u001b[38;5;124m\"\u001b[39m, [])) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28;01mraise\u001b[39;00m UnknownValueError()\n\u001b[0;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfidence\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m actual_result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malternative\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    731\u001b[0m     \u001b[38;5;66;03m# return alternative with highest confidence score\u001b[39;00m\n\u001b[0;32m    732\u001b[0m     best_hypothesis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(actual_result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malternative\u001b[39m\u001b[38;5;124m\"\u001b[39m], key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m alternative: alternative[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfidence\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n","\u001b[1;31mUnknownValueError\u001b[0m: "]}],"source":["#If the Speech is unrecognizable then it will give UnknownValueError.\n","\n","import speech_recognition as sr\n","r = sr.Recognizer()\n","mic = sr.Microphone()\n","with mic as source:\n","    r.adjust_for_ambient_noise(source)\n","    audio = r.listen(source)\n","    \n","r.recognize_google(audio)"]},{"cell_type":"markdown","id":"e42df583","metadata":{"id":"e42df583"},"source":["# Speech Recognition Model\n","\n","## Speech Recognition in English"]},{"cell_type":"code","execution_count":null,"id":"1b9d60b0","metadata":{"id":"1b9d60b0","outputId":"77576b20-1fa4-442e-8488-2f20e2824657"},"outputs":[{"name":"stdout","output_type":"stream","text":["Listening...\n","You said: my name is Harsh and I am a student in D Y Patil International University of BTech 3rd year\n"]}],"source":["import speech_recognition as sr\n","\n","# Initialize the recognizer\n","r = sr.Recognizer()\n","\n","# Record audio from the microphone\n","mic = sr.Microphone()\n","with mic as source:\n","    r.adjust_for_ambient_noise(source)\n","    print(\"Listening...\")\n","    audio = r.listen(source)\n","\n","# Perform speech recognition    \n","try:\n","    text = r.recognize_google(audio)\n","    print(\"You said:\", text)\n","except sr.UnknownValueError:\n","    print(\"Speech recognition could not understand audio\")\n","except sr.RequestError as e:\n","    print(\"Could not request results from speech recognition service; {0}\".format(e))"]},{"cell_type":"code","execution_count":null,"id":"feab16f8","metadata":{"id":"feab16f8","outputId":"e38559a7-39c6-43d4-ecab-f18de9a06b86"},"outputs":[{"name":"stdout","output_type":"stream","text":["It has stored speech into text in my_speech.txt file\n"]}],"source":["#If you want to export the result then use\n","with open('my_speech.txt',mode = 'w') as file:\n","    file.write(text)\n","    \n","print(\"It has stored speech into text in my_speech.txt file\")        "]},{"cell_type":"markdown","id":"41d59700","metadata":{"id":"41d59700"},"source":["## Speech Recognition in Hindi"]},{"cell_type":"code","execution_count":null,"id":"90dc5bcf","metadata":{"id":"90dc5bcf","outputId":"e5b1fcc9-af31-4bcc-9cd2-c3292f957aff"},"outputs":[{"name":"stdout","output_type":"stream","text":["Listening...\n","You said: मेरा नाम हर्ष है और मैं डीवाई पाटिल अंतरराष्ट्रीय यूनिवर्सिटी में पढ़ता हूं\n","It has stored speech into text in my_speech_Hindi.txt file\n"]}],"source":["import speech_recognition as sr\n","\n","# Initialize the recognizer\n","r = sr.Recognizer()\n","\n","# Record audio from the microphone\n","mic = sr.Microphone()\n","with mic as source:\n","    r.adjust_for_ambient_noise(source)\n","    print(\"Listening...\")\n","    audio = r.listen(source)\n","\n","# Perform speech recognition    \n","try:\n","    text = r.recognize_google(audio, language='hi-IN')\n","    print(\"You said:\", text)\n","except sr.UnknownValueError:\n","    print(\"Speech recognition could not understand audio\")\n","except sr.RequestError as e:\n","    print(\"Could not request results from speech recognition service; {0}\".format(e))\n","\n","# export the result\n","\n","with open('my_speech_Hindi.txt',mode = 'w', encoding='utf-8') as file:\n","    file.write(text)\n","#in the above line encoding parameter is set to 'utf-8' to handle the Unicode characters.     \n","\n","print(\"It has stored speech into text in my_speech_Hindi.txt file\")\n"]},{"cell_type":"markdown","id":"bcd22bab","metadata":{"id":"bcd22bab"},"source":["## Speech Recognition in both languages (Hindi and English)"]},{"cell_type":"code","execution_count":null,"id":"dff07ed0","metadata":{"id":"dff07ed0","outputId":"e55b66af-59e3-4840-c397-de57037b9b1f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Listening...\n","You said: आई एम ए स्टूडेंट इन डी पाटील इंटरनेशनल यूनिवर्सिटी\n","You said: I am a student in D Y Patil International University\n","It has stored speech into text in my_speech_hindi_english_1.txt file\n","It has stored speech into text in my_speech_hindi_english_2.txt file\n"]}],"source":["import speech_recognition as sr\n","\n","# Initialize the recognizer\n","r = sr.Recognizer()\n","\n","# Record audio from the microphone\n","mic = sr.Microphone()\n","with mic as source:\n","    r.adjust_for_ambient_noise(source)\n","    print(\"Listening...\")\n","    audio = r.listen(source)\n","\n","# Perform speech recognition    \n","try:\n","    text_hi = r.recognize_google(audio, language='hi-IN')\n","    print(\"You said:\", text_hi)\n","    \n","    text_en = r.recognize_google(audio, language='en-US')\n","    print(\"You said:\", text_en)\n","    \n","except sr.UnknownValueError:\n","    print(\"Speech recognition could not understand audio\")\n","except sr.RequestError as e:\n","    print(\"Could not request results from speech recognition service; {0}\".format(e))\n","\n","# export the result\n","with open('my_speech_hindi_english_1.txt',mode = 'w', encoding='utf-8') as file:\n","    file.write(text_hi)\n","    \n","print(\"It has stored speech into text in my_speech_hindi_english_1.txt file\")\n","\n","with open('my_speech_hindi_english_2',mode = 'w', encoding='utf-8') as file:\n","    file.write(text_en)\n","    \n","print(\"It has stored speech into text in my_speech_hindi_english_2.txt file\")"]},{"cell_type":"markdown","id":"bb6e0ea4","metadata":{"id":"bb6e0ea4"},"source":["## Link used to download audio\n","http://www.voiptroubleshooter.com/open_speech/american.html"]},{"cell_type":"code","execution_count":null,"id":"211f1413","metadata":{"id":"211f1413"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}